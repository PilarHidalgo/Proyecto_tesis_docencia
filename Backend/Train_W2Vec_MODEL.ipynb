{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Entrenamiento del modelo en español Word2Vec**\n",
        "Primero se investigó acerca de modelos en español, entrenados para reconocimiento y segmentación de palabras (tokenización) en español. Uno de los más completos fue \"cc.es.300.vec.gz\". Disponible en: https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "\n",
        "Distribuimos vectores de palabras previamente entrenados para 157 idiomas, entrenados en Common Crawl y Wikipedia usando fastText. Estos modelos fueron entrenados utilizando CBOW con posición-pesos, en dimensión 300, con caracteres n-gramas de longitud 5, ventana de tamaño 5 y 10 negativos. También distribuimos tres nuevos conjuntos de datos de analogía de palabras, para francés, hindi y polaco. Puede encontrar más información sobre el entrenamiento de estos modelos en el artículo Aprendiendo vectores de palabras para 157 idiomas.\n",
        "\n",
        "**Licencia:** Creative Commons Attribution-Share-Alike License 3.0.\n",
        "\n",
        "**Referencias**: El artículo referenciado es: [E. Grave*, P. Bojanowski*, P. Gupta, A. Joulin, T. Mikolov, Learning Word Vectors for 157 Languages](https://arxiv.org/abs/1802.06893)\n",
        "\n",
        "Otros recursos de código: https://github.com/pushpendudas/custom_word2vec_model_training/blob/master/word2vec%20training.ipynb"
      ],
      "metadata": {
        "id": "J17eTV2n_wtb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reZGnbPMnZUw",
        "outputId": "fb03f921-68b4-40c6-d0ea-2836d9aaa6b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 2.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=a4207ab14285bf4aca812669b3886b63e2a488c1deceb0ee6673e106ad4c08ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ]
        }
      ],
      "source": [
        "#INSTALAR LIBRERIAS\n",
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2CF0rRcXkRM"
      },
      "outputs": [],
      "source": [
        "#Medición de las Dimensión socio-cultural: aparte del ODS,trasnversal ala agenda unsco 2030\n",
        "#https://lab.ccesv.org/los-derechos-culturales-como-parte-de-la-agenda-2030-es-posible-su-cumplimiento-tras-la-pandemia/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38qOmSzTndCW",
        "outputId": "17dead12-5c7a-4343-cc64-c525cff9e29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ]
        }
      ],
      "source": [
        "#IMPORTAR LIBRERIAS\n",
        "import os, sys\n",
        "import seaborn as sns\n",
        "#import PyPDF2\n",
        "from nltk import Tree\n",
        "from spacy import displacy\n",
        "from spacy.pipeline import DependencyParser\n",
        "import re\n",
        "import spacy\n",
        "from spacy.lang.es import Spanish\n",
        "from spacy.pipeline import EntityRuler\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.data import load\n",
        "from string import punctuation\n",
        "nltk.download('stopwords')\n",
        "spanish_stopwords=stopwords.words('spanish')\n",
        "non_words=list(punctuation)\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from itertools import chain\n",
        "import more_itertools as mit\n",
        "from nltk.corpus import names \n",
        "from nltk.corpus.reader.util import *\n",
        "import nltk \n",
        "from nltk import precision\n",
        "import collections\n",
        "import nltk.metrics\n",
        "from nltk.tokenize import MWETokenizer\n",
        "nltk.download('names')\n",
        "import random \n",
        "from nltk.corpus import names \n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Futhn8xDv0EU"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm, trange, tqdm_notebook\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YqyNa89ap2w"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KT3pBclvYGm"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDooGK_xvaYo"
      },
      "outputs": [],
      "source": [
        "#IMPORTAR EL MODELO DESDE EL DRIVE, TAMBIEN SE PUEDEN SEGUIR LAS INSTRUCCIONES DE \n",
        "#https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "downloaded = drive.CreateFile({'id':\"XXX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('cc.es.300.vec.gz') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gga6Gooq_TYA"
      },
      "outputs": [],
      "source": [
        "downloaded = drive.CreateFile({'id':\"XXX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('ODS (1).pdf') \n",
        "downloaded = drive.CreateFile({'id':\"XXX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('ODS (2).pdf') \n",
        "downloaded = drive.CreateFile({'id':\"XXX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('ODS (3).pdf') \n",
        "downloaded = drive.CreateFile({'id':\"XXX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('ODS (4).pdf') \n",
        "downloaded = drive.CreateFile({'id':\"XX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Lineas_Concytec.pdf')\n",
        "downloaded = drive.CreateFile({'id':\"XX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('NCUBE_LINES.pdf')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U1HZpX2va_B"
      },
      "outputs": [],
      "source": [
        "#ABRIR EL MODELO\n",
        "import gzip \n",
        "import shutil \n",
        "with gzip.open('cc.es.300.vec.gz', 'rb') as f_in: \n",
        "  with open('cc.es.300.vec', 'wb') as f_out: \n",
        "    shutil.copyfileobj(f_in, f_out) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S1gGwFoYvdCH"
      },
      "outputs": [],
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "#LEER EL MODELO EN ESPAÑOL DE WORD2VEC\n",
        "wordvectors_file_vec = 'cc.es.300.vec'#wiki.es.vec'#'cc.es.300.vec'\n",
        "cantidad = 100000\n",
        "wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yAmPZzBvfcx",
        "outputId": "5428b5c1-63b7-402f-ae6c-33ba284afa65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('patrimonio', 0.8957945108413696),\n",
              " ('patrimoniales', 0.865646481513977),\n",
              " ('Patrimonial', 0.8525913953781128),\n",
              " ('patrimonios', 0.8207882046699524),\n",
              " ('cultural', 0.8054655194282532),\n",
              " ('Patrimonio', 0.7939102649688721),\n",
              " ('histórico-artístico', 0.7744946479797363),\n",
              " ('arquitectónico', 0.7725043296813965),\n",
              " ('paisajístico', 0.7723819017410278),\n",
              " ('jurídico', 0.7638840079307556)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#PROBAR EL MODELO EN BLANCO\n",
        "wordvectors.most_similar_cosmul('patrimonial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enWFEufnviIj",
        "outputId": "8d2876e3-6306-48eb-9638-6916ab834fd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5924913"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordvectors.similarity('sostenibilidad', 'ambiental')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZTl1Qcaneqg"
      },
      "outputs": [],
      "source": [
        "#LISTAR LOS DOCUMENTOS OFICIALES\n",
        "nombres=['ODS (1).pdf',\n",
        "        'ODS (2).pdf',\n",
        "        'ODS (3).pdf',\n",
        "        'ODS (4).pdf']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LEER TODOS LOS PDF\n",
        "i=0\n",
        "for archivo in nombre:\n",
        "  i=i+1\n",
        "  exec(f'pdfFileObj{i} = open(nombre[i], \"rb\")')\n",
        "  exec(f'pdfReader{i} = PyPDF2.PdfFileReader(pdfFileObj{i})')\n",
        "  exec(f'Pages=pdfReader{i}.numPages')## LEER PDF DE LEY Y CONVERTIR A TEXTO PLANO\n",
        "  #Almacenar el contenido por paginas\n",
        "  Caps=[]\n",
        "  for k in trange(0,Pages):\n",
        "      exec(f'pageObj = pdfReader{i}.getPage(k)')\n",
        "      Cap=pageObj.extractText()#.encode('utf8')\n",
        "      Caps.append(Cap)\n",
        "      XX={'Texto'}\n",
        "  exec(f'df{i}=pd.DataFrame(Caps,columns=XX)')\n",
        "  exec(f'df{i}[\"Archivo\"]=nombres[i]')"
      ],
      "metadata": {
        "id": "VEhPBCMbDG_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tmzaxc4wqOSb"
      },
      "outputs": [],
      "source": [
        "i=1#,2,3,4\n",
        "df=pd.DataFrame(Caps,columns={'Texto'})\n",
        "df['Archivo']=nombre[i]\n",
        "df1=pd.DataFrame(Caps,columns={'Texto'})\n",
        "df1['Archivo']=nombre[i]\n",
        "df2=pd.DataFrame(Caps,columns={'Texto'})\n",
        "df2['Archivo']=nombre[i]\n",
        "df3=pd.DataFrame(Caps,columns={'Texto'})\n",
        "df3['Archivo']=nombre[i]\n",
        "df4=pd.DataFrame(Caps,columns={'Texto'})\n",
        "df4['Archivo']=nombre[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGjXf_4vrck1"
      },
      "outputs": [],
      "source": [
        "db=[df,df1,df2,df3,df4]\n",
        "result=pd.concat(db,ignore_index=True)\n",
        "len(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7CNB_vHUsGfj"
      },
      "outputs": [],
      "source": [
        "#PREPROCESO DE TEXTO\n",
        "def preprocess(text):\n",
        "    nlp = Spanish()\n",
        "    result= []\n",
        "    for i in trange(0,len(text)):\n",
        "        text[i]=str(text[i])\n",
        "        text[i]=re.sub(u'^(?<![a-z A-Z])',' ',text[i])\n",
        "        text[i]=text[i].lower()\n",
        "        text[i]=text[i].replace('\"',' ')\n",
        "        text[i]=text[i].replace('(',' ')\n",
        "        text[i]=text[i].replace(')',' ')\n",
        "        text[i]=text[i].replace('\\n',' ')\n",
        "        text[i]=text[i].replace(']',' ')\n",
        "        text[i]=text[i].replace('[',' ')\n",
        "        text[i]=text[i].replace('/',' ')\n",
        "        text[i]=text[i].replace('%',' ')\n",
        "        text[i]=text[i].replace('+',' ')\n",
        "        text[i]=text[i].replace('-',' ')\n",
        "        text[i]=text[i].replace('.',' ')\n",
        "        text[i]=text[i].replace(';',' ')\n",
        "        text[i]=text[i].replace('\\n',' ')\n",
        "        text[i]=text[i].replace(':',' ')\n",
        "        text[i]=text[i].replace('|',' ')\n",
        "        text[i]=text[i].replace('*',' ')\n",
        "        text[i]=text[i].replace('—',' ')\n",
        "        text[i]=text[i].replace('€',' ')\n",
        "        text[i]=text[i].replace('\\\\n',' ')\n",
        "        text[i]=text[i].replace(',','')\n",
        "        text[i]=text[i].replace(' ma ','')\n",
        "        text[i]=text[i].replace(' aqui ','')\n",
        "        text[i]=text[i].replace('cuales ','')\n",
        "        text[i]=text[i].replace('toda ','')\n",
        "        text[i]=text[i].replace('cada ','')\n",
        "        text[i]=text[i].replace(' lo ','')\n",
        "        a,b = 'áéíóúü','aeiouu'\n",
        "        trans = str.maketrans(a,b)\n",
        "        text[i]=text[i].translate(trans)\n",
        "        text[i]=text[i].strip()\n",
        "        doc=nlp(text[i])\n",
        "        t=[token.text for token in doc]\n",
        "        result.append(' '.join(list(t)))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8XfWUo-sNi-"
      },
      "outputs": [],
      "source": [
        "result['Prep_text']=preprocess(result['Texto'])\n",
        "result['Prep_text'][8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "craVCrcL1eYK"
      },
      "outputs": [],
      "source": [
        "# Loading libraries\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Bub-P961qZR",
        "outputId": "59cdd3a7-67b8-492e-8daa-533eeacb42fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time:\t 0.0\n"
          ]
        }
      ],
      "source": [
        "# Time calculation\n",
        "def cal_elapsed_time(s):\n",
        "    return print(\"Elapsed time:\\t\", round((time.time() - s),2))\n",
        "s_time = time.time()\n",
        "cal_elapsed_time(s=s_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kcu43pG2BWY"
      },
      "outputs": [],
      "source": [
        "#OBTENER LA INFORMACION\n",
        "data_df=result#.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MaCbD872e5E"
      },
      "outputs": [],
      "source": [
        "#Model training\n",
        "#Using Gensim model to triain word2vec model\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w5eSB8j2ffM"
      },
      "outputs": [],
      "source": [
        "s_time = time.time()\n",
        "print(\"Model Training Started...\")\n",
        "####wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)\n",
        "#### model =wordvectors(sentences=sent_corpus, size=200, window=4, min_count=1, workers=4)\n",
        "#model = Word2Vec(sentences=sent_corpus, size=200, window=4, min_count=1, workers=4)\n",
        "cal_elapsed_time(s_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RlwRWXE2h4s"
      },
      "outputs": [],
      "source": [
        "print(\"Total number of unique words loaded in Model : \", len(model.wv.vocab))#3300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FG11BbF2kHv"
      },
      "outputs": [],
      "source": [
        "#GUARDAR EL MODELO\n",
        "model.save(\"data/model/trainned_model.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYifhfiI2pSJ",
        "outputId": "446bbf6d-361b-41e9-9146-9aa25c8ac057"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('sostenible', 0.8844438195228577),\n",
              " ('persona', 0.8756629228591919),\n",
              " ('desarrollo', 0.8702710270881653),\n",
              " ('recursos', 0.8692913055419922),\n",
              " ('mujeres', 0.8688398599624634),\n",
              " ('dea', 0.8618358373641968),\n",
              " ('proporcion', 0.8614614009857178),\n",
              " ('paises', 0.8496870994567871),\n",
              " ('nacionales', 0.8466477990150452),\n",
              " ('ma', 0.8452156186103821),\n",
              " ('servicios', 0.844576358795166),\n",
              " ('toda', 0.8400709629058838),\n",
              " ('numero', 0.8389781713485718),\n",
              " ('sostenibles', 0.838219165802002),\n",
              " ('mundial', 0.8336294293403625),\n",
              " ('agenda', 0.8332079648971558),\n",
              " ('acceso', 0.8326206207275391),\n",
              " ('promover', 0.832047700881958),\n",
              " ('trabajo', 0.8317737579345703),\n",
              " ('consumo', 0.8223632574081421)]"
            ]
          },
          "execution_count": 339,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find similar words for efficiency\n",
        "model.wv.most_similar(\"agua\", topn=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAXfL7dY22f3",
        "outputId": "ac983692-33c2-4945-99f0-35c207344b4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6695497"
            ]
          },
          "execution_count": 329,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List of word similarity\n",
        "model.wv.n_similarity(['igualdad','mujer'],['genero','mujeres'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnsWAJdz24q1",
        "outputId": "238a468d-03d4-4534-edc4-9cf191ab1454"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8909858763217926"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distance between two words\n",
        "model.wv.distance('igualdad','mujer')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTANTE: Para conocer las palabras similares en los dicionarios, se construyen segun los temas por ejemplo: Para DSA: ambiente o ambiental o lo relacionado con medios urbanos se lista"
      ],
      "metadata": {
        "id": "D_ySGIP1Edsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vLMmSiY6Ecfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Train_W2Vec_MODEL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}